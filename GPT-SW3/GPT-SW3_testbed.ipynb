{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESEARCH: Fine tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login  \n",
    "login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline, GPTSw3Tokenizer , AutoModelForCausalLM\n",
    "\n",
    "# Model name: AI-Sweden-Models/gpt-sw3-126m, AI-Sweden-Models/gpt-sw3-1.3b\n",
    "model_name = \"AI-Sweden-Models/gpt-sw3-356m-instruct\"\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\" #in case i run this on my laptop or pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPTSw3Tokenizer.from_pretrained(model_name, use_auth_token=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <|endoftext|><s> User: Hur fungerar hjärnan?<s>Bot: Den mänskliga hjärnan är en komplex organisme som består av flera kammare och neuroner, som ansvarar för att bearbeta och bearbeta information. Dessa kammare är involverade i regleringen av nervsystemet, hjärnans metabolism, psykisk funktion och även känslor och beteende.\n",
      "\n",
      "Hjärnans utveckling går långsamt, vilket gör att den inte har nått sin fullbordade form än. Men hittills har forskare varit framgångsrika i att studera hjärnan och försöka förstå hur den fungerar.\n",
      "\n",
      "Till exempel har forskare studerat hjärnans\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "<|endoftext|><s>\n",
    "User: Hur fungerar hjärnan?\n",
    "<s>\n",
    "Bot:\n",
    "\"\"\".strip()\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "\n",
    "generated_token_ids = model.generate(\n",
    "    inputs=input_ids,\n",
    "    max_new_tokens=100,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=1,\n",
    ")[0]\n",
    "\n",
    "generated_text = tokenizer.decode(generated_token_ids)   \n",
    "\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
