{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login  \n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, StoppingCriteriaList, StoppingCriteria\n",
    "\n",
    "# Initialize Variables\n",
    "model_name = \"AI-Sweden-Models/gpt-sw3-1.3b\"\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\" #in case i run this on my laptop or pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize Tokenizer & Model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoppingCriteriaSub(StoppingCriteria):\n",
    "\n",
    "    def __init__(self, stops = [], encounters=1):\n",
    "        super().__init__()\n",
    "        self.stops = [stop.to(\"cuda\") for stop in stops]\n",
    "\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor):\n",
    "        for stop in self.stops:\n",
    "            if torch.all((stop == input_ids[0][-len(stop):])).item():\n",
    "                return True\n",
    "\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Följande är en konversation mellan en besökare på museet och en guide. Guiden arbetar på museet. Guiden är hjälpsam, informativ och mycket vänlig.Museet innehåller tre utställningar, den första utställningen heter 'Hitta nemo igen' av Hermann Gustafsson. Guiden ska hjälpa besökaren med frågor.\n",
      "\n",
      "Besökare: Hej, jag är här för att se utställningen 'Hitta nemo igen', och jag har en fråga!\n",
      "Guide: Hej, vad kul! Vad vill du veta om utställningen?\n",
      "Besökare: Vet du vem som skapade utställningen?\n",
      "Guide: Ja, det är Hermann Gustafsson!\n",
      "Besökare: Tack så mycket, vad bra!\n",
      "Guide: Vad bra, då kan du gå och titta på utställningen!\n",
      "Besökare: Tack så mycket!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_text(prompt):\n",
    "    stop_words = [\"Besökare:\", \"Guide:\"]\n",
    "    stop_ids = [tokenizer.encode(stop_word, return_tensors=\"pt\") for stop_word in stop_words]\n",
    "    stopping_criteria = StoppingCriteriaList([StoppingCriteriaSub(stops = stop_ids)])\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    output = model.generate(\n",
    "        inputs = input_ids,\n",
    "        max_new_tokens = 50,\n",
    "        do_sample=True,\n",
    "        top_p=1, temperature=0.5,\n",
    "        stopping_criteria=stopping_criteria\n",
    "        )\n",
    "    return tokenizer.decode(output[0] , skip_special_tokens=True)\n",
    "\n",
    "prompt = \"Följande är en konversation mellan en besökare på museet och en guide. Guiden arbetar på museet. Guiden är hjälpsam, informativ och mycket vänlig.\" \\\n",
    "            \"Museet innehåller tre utställningar, den första utställningen heter 'Hitta nemo igen' av Hermann Gustafsson. Guiden ska hjälpa besökaren med frågor.\\n\\n\"\\\n",
    "            \"Besökare: Hej, jag är här för att se utställningen 'Hitta nemo igen', och jag har en fråga!\\n\" \\\n",
    "            \"Guide: Hej, vad kul! Vad vill du veta om utställningen?\\n\" \\\n",
    "            \"Besökare: Vet du vem som skapade utställningen?\\n\" \\\n",
    "            \"Guide\"\n",
    "print(generate_text(prompt))         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
