{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-SW3\n",
    "https://nlu-lab.notion.site/Prompthandboken-7cd943cc230642f2b8243807731e81ae\n",
    "  \n",
    "Fick inbjudan genom att anmäla mig via denna länk: https://docs.google.com/forms/d/e/1FAIpQLSebZv__Me6YUO_kFetDZevwXgSsYSVnXWzG5H68MIwN4XmdtQ/viewform\n",
    "\n",
    "Borde inte ta långt innan man får mejl, men hör av om det tar för lång tid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login  \n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Initialize Variables\n",
    "model_name = \"AI-Sweden-Models/gpt-sw3-1.3b\"\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\" #in case i run this on my laptop or pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize Tokenizer & Model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Följande är en konversation mellan en besökare på museet och en guide. Guiden arbetar på museet. Guiden är hjälpsam, informativ och mycket vänlig. \n",
      "Museet innehåller tre utställningar, den första utställningen heter 'Hitta nemo igen' av Hermann Gustafsson \n",
      "\n",
      "\n",
      "Besökare: Hej, jag är här för att se utställningen 'Hitta nemo igen', och jag har en fråga!\n",
      "Guide: Hej, vad kul! Vad vill du veta om utställningen?\n",
      "Besökare: Vet du vem som skapade utställningen?\n",
      "Guide: Ja, det är Hermann Gustafsson, hans son.\n",
      "Besökare: Är ni släkt?\n",
      "Guide: Nej, det är inte vi.\n",
      "Besökare: Ok, jag förstår.\n",
      "\n",
      "\n",
      "Besökare: Hej, jag är intresserad av din familj. Hur många barn har ni?\n",
      "Guide: Hej! Jag har tre barn, två flickor och en pojke.\n",
      "Besökare: Ok, är dina barn här?\n",
      "Guide: Ja, de bor hos sin mamma.\n",
      "Besökare: Ok, ska vi gå till det här rummet?\n",
      "Guide: Ja, det tycker jag.\n",
      "Besökare: Ok, jag har en fråga till!\n",
      "Guide: Ok, vad vill du veta om utställningen?\n",
      "Besökare: Vem uppfann den?\n",
      "Guide: Hermann Gustafsson, hans son.\n",
      "Besökare: Ok, tack för hjälpen!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_text(prompt):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    output = model.generate(\n",
    "        inputs = input_ids,\n",
    "        max_new_tokens = 200,\n",
    "        do_sample=True,\n",
    "        top_p=1, temperature=0.7\n",
    "        )\n",
    "    return tokenizer.decode(output[0])\n",
    "\n",
    "prompt = \"Följande är en konversation mellan en besökare på museet och en guide. Guiden arbetar på museet. Guiden är hjälpsam, informativ och mycket vänlig. \\n\" \\\n",
    "            \"Museet innehåller tre utställningar, den första utställningen heter 'Hitta nemo igen' av Hermann Gustafsson \\n\\n\\n\"\\\n",
    "            \"Besökare: Hej, jag är här för att se utställningen 'Hitta nemo igen', och jag har en fråga!\\n\" \\\n",
    "            \"Guide: Hej, vad kul! Vad vill du veta om utställningen?\\n\" \\\n",
    "            \"Besökare: Vet du vem som skapade utställningen?\\n\" \n",
    "print(generate_text(prompt))         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
